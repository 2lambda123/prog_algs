{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "d7f94b8b1e41b02170d45ac71ce2d6b011e7cd56207b4c480f5292088bcfab93"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Welcome to the Prognostics Algorithms Package Tutorial"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The goal of this notebook is to instruct the user on how to use and extend the NASA Python Prognostics Algorithms Package. \n",
    "\n",
    "First some background. The Prognostics Algorithms Package (`prog_algs`) contains tools for performing prognostics (event prediction) using the Prognostics Models Package. `prog_algs` also includes tools for analyzing the performance of prognostics algorithms. \n",
    "\n",
    "A few definitions:\n",
    "* state estimation: The process of estimating the (possibly hidden) state of a system given sensor information on observable states\n",
    "* prediction: The process of predicting the evolution of a system state with time and the occurance of events. \n",
    "\n",
    "The `prog_algs` package has the following structure\n",
    "* `prog_algs/state_estimators/` - Tools for performing state estimation\n",
    "* `prog_algs/predictors/` - Tools for performing prediction\n",
    "* `prog_algs/metrics/` - Tools for analyzing the performance of prognostics algorithms\n",
    "* `prog_algs/samplers/` - Tools for sampling from a distribution\n",
    "\n",
    "In addition to the `prog_algs` package, this repo includes examples showing how to use the package (see `examples/`), a template for implementing a new state estimator (`state_estimator_template`), a template for implementing a new predictor (`predictor_template`), documentation (`docs/`), and this tutorial (`tutorial.ipynb`).\n",
    "\n",
    "Before you start, make sure that all the required packages are installed (defined in `requirements.txt`)\n",
    "\n",
    "Now lets get started with some examples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Prediction Example \n",
    "First thing to do is to import the prog_algs and the model you intend to use"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.insert(1, \"/Users/cteubert/Desktop/python-prognostics-models-package/\")\n",
    "sys.path.insert(1, \"../python-prognostics-models-package/\")\n",
    "from prog_models.models import battery_circuit\n",
    "from prog_algs import *"
   ]
  },
  {
   "source": [
    "Next, prepare the model like you did for simulation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def future_loading(t):\n",
    "    # Variable (piece-wise) future loading scheme \n",
    "    if (t < 600):\n",
    "        i = 2\n",
    "    elif (t < 900):\n",
    "        i = 1\n",
    "    elif (t < 1800):\n",
    "        i = 4\n",
    "    elif (t < 3000):\n",
    "        i = 2\n",
    "    else:\n",
    "        i = 3\n",
    "    return {'i': i}\n",
    "\n",
    "batt = battery_circuit.BatteryCircuit()"
   ]
  },
  {
   "source": [
    "Now that we have our model ready, we can construct our state estimator:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = state_estimators.unscented_kalman_filter.UnscentedKalmanFilter(batt, batt.parameters['x0'])"
   ]
  },
  {
   "source": [
    "The filter estimate function can then be run when there is updated data. Each iteration it will produce a new estimate of the system state (with uncertainty). For example:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prior State: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0.0, 'qcs': 0.0}\n\tSOC:  1.0\nPosterior State: {'tb': 31.00563722940381, 'qb': 7856.028911363359, 'qcp': 0.3627028293822553, 'qcs': 0.30274934527534775}\n\tSOC:  0.999961876220054\n"
     ]
    }
   ],
   "source": [
    "print(\"Prior State:\", filt.x.mean)\n",
    "print('\\tSOC: ', batt.event_state(filt.t, filt.x.mean)['EOD'])\n",
    "example_measurements = {'t': 32.2, 'v': 3.915}\n",
    "t = 0.1\n",
    "filt.estimate(t, future_loading(t), example_measurements)\n",
    "print(\"Posterior State:\", filt.x.mean)\n",
    "print('\\tSOC: ', batt.event_state(filt.t, filt.x.mean)['EOD'])"
   ]
  },
  {
   "source": [
    "That's the state estimation step- now lets prepare for prediction. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = predictors.monte_carlo.MonteCarlo(batt)\n",
    "samples = filt.x.sample(20)\n",
    "prediction_config = {'dt': 0.025}"
   ]
  },
  {
   "source": [
    "Now lets use the constructed mc predictor to perform a single prediction. Note this may take up to a minute"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(times, inputs, states, outputs, event_states, eol) = mc.predict(samples, future_loading, prediction_config)\n"
   ]
  },
  {
   "source": [
    "Next, let's use the metrics package to analyse the results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nEOD Predictions (s):\n\tPercentage between 3005.2 and 3005.6:  70.0 %\n\tAssuming ground truth 3005.25:  {'min': 3005.0500000065495, 'percentiles': {'0.01': None, '0.1': None, '1': None, '10': 3005.1250000065497, '25': 3005.25000000655, '50': 3005.3500000065505, '75': 3005.425000006551}, 'median': 3005.3500000065505, 'mean': 3005.3312500065504, 'std': 0.16083279360935132, 'max': 3005.6750000065517, 'median absolute deviation': 0.1212500000004411, 'mean absolute deviation': 0.1212500000004411, 'number of samples': 20, 'mean absolute error': 0.1462500032756225, 'mean absolute percentage error': 4.866483762602861e-05, 'relative accuracy': 0.9999729639775226, 'ground truth percentile': 25.0}\n\tP(Success) if mission ends at 3005.25:  0.75\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEOD Predictions (s):\")\n",
    "from prog_algs.metrics import samples as metrics \n",
    "print('\\tPercentage between 3005.2 and 3005.6: ', metrics.percentage_in_bounds(eol, [3005.2, 3005.6])*100.0, '%')\n",
    "print('\\tAssuming ground truth 3005.25: ', metrics.eol_metrics(eol, 3005.25))\n",
    "print('\\tP(Success) if mission ends at 3005.25: ', metrics.prob_success(eol, 3005.25))"
   ]
  },
  {
   "source": [
    "## Extending - Adding a new state estimator\n",
    "New state estimators can be created by extending the state_estimator interface. As an example lets use a really dumb state estimator that adds random noise each step - and accepts the state that is closest. \n",
    "\n",
    "First thing we need to do is import the StateEstimator parent class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prog_algs.state_estimators.state_estimator import StateEstimator"
   ]
  },
  {
   "source": [
    "Next we select how state will be represented. In this case there's no uncertainty- it's just one state, so we represent it as a scaler. Import the appropriate class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prog_algs.uncertain_data import ScalarData"
   ]
  },
  {
   "source": [
    "Now we construct the class, implementing the functions of the state estimator template"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "class BlindlyStumbleEstimator(StateEstimator):\n",
    "    def __init__(self, model, x0):\n",
    "        self.m = model\n",
    "        self.state = x0\n",
    "\n",
    "    def estimate(self, t, u, z):\n",
    "        # Generate new candidate state\n",
    "        x2 = {key : float(value) + 10*(random.random()-0.5) for (key,value) in self.state.items()}\n",
    "\n",
    "        # Calculate outputs\n",
    "        z_est = self.m.output(t, self.state)\n",
    "        z_est2 = self.m.output(t, x2)\n",
    "\n",
    "        # Now score them each by how close they are to the measured z\n",
    "        z_est_score = sum([abs(z_est[key] - z[key]) for key in self.m.outputs])\n",
    "        z_est2_score = sum([abs(z_est2[key] - z[key]) for key in self.m.outputs])\n",
    "\n",
    "        # Now choose the closer one\n",
    "        if z_est2_score < z_est_score: \n",
    "            self.state = x2\n",
    "\n",
    "    @property\n",
    "    def x(self):\n",
    "        return ScalarData(self.state)\n"
   ]
  },
  {
   "source": [
    "Great, now let's try it out using the model from earlier. with an initial state of all 0s. It should slowly converge at the correct state"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'tb': 0, 'qb': 0, 'qcp': 0, 'qcs': 0}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 4.320252397366701, 'qb': 0.2669156472025269, 'qcp': 2.5015399743778852, 'qcs': -4.011339024143258}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 7.4584828023047525, 'qb': 0.04574684468407586, 'qcp': 5.89654519740461, 'qcs': -4.003468940183254}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 8.270665429473192, 'qb': 3.1273638795646006, 'qcp': 2.0540303322185265, 'qcs': -6.173375820837325}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 8.270665429473192, 'qb': 3.1273638795646006, 'qcp': 2.0540303322185265, 'qcs': -6.173375820837325}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 8.270665429473192, 'qb': 3.1273638795646006, 'qcp': 2.0540303322185265, 'qcs': -6.173375820837325}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 8.270665429473192, 'qb': 3.1273638795646006, 'qcp': 2.0540303322185265, 'qcs': -6.173375820837325}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 11.739852535820727, 'qb': 5.593749278514163, 'qcp': 2.738045485036769, 'qcs': -7.864003163531933}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 11.739852535820727, 'qb': 5.593749278514163, 'qcp': 2.738045485036769, 'qcs': -7.864003163531933}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 15.17960733952922, 'qb': 2.6133319828271606, 'qcp': 3.5248778485152172, 'qcs': -7.13786388306146}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 15.17960733952922, 'qb': 2.6133319828271606, 'qcp': 3.5248778485152172, 'qcs': -7.13786388306146}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 16.971291499577962, 'qb': 4.090825046327513, 'qcp': 4.0863613488981265, 'qcs': -5.4908845764158745}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 16.971291499577962, 'qb': 4.090825046327513, 'qcp': 4.0863613488981265, 'qcs': -5.4908845764158745}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 18.071257553833224, 'qb': 8.861915742524467, 'qcp': 7.781344872433501, 'qcs': -2.118860872323296}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 18.071257553833224, 'qb': 8.861915742524467, 'qcp': 7.781344872433501, 'qcs': -2.118860872323296}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 18.071257553833224, 'qb': 8.861915742524467, 'qcp': 7.781344872433501, 'qcs': -2.118860872323296}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 18.071257553833224, 'qb': 8.861915742524467, 'qcp': 7.781344872433501, 'qcs': -2.118860872323296}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 18.071257553833224, 'qb': 8.861915742524467, 'qcp': 7.781344872433501, 'qcs': -2.118860872323296}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 18.071257553833224, 'qb': 8.861915742524467, 'qcp': 7.781344872433501, 'qcs': -2.118860872323296}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 18.071257553833224, 'qb': 8.861915742524467, 'qcp': 7.781344872433501, 'qcs': -2.118860872323296}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 18.071257553833224, 'qb': 8.861915742524467, 'qcp': 7.781344872433501, 'qcs': -2.118860872323296}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 18.071257553833224, 'qb': 8.861915742524467, 'qcp': 7.781344872433501, 'qcs': -2.118860872323296}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 18.071257553833224, 'qb': 8.861915742524467, 'qcp': 7.781344872433501, 'qcs': -2.118860872323296}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 19.5139512225883, 'qb': 11.174507157390781, 'qcp': 5.710527969029882, 'qcs': 1.8710487514002985}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n{'tb': 19.5139512225883, 'qb': 11.174507157390781, 'qcp': 5.710527969029882, 'qcs': 1.8710487514002985}\n\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\n"
     ]
    }
   ],
   "source": [
    "x0 = {key: 0 for key in batt.states}\n",
    "se = BlindlyStumbleEstimator(batt, x0)\n",
    "\n",
    "for i in range(25):\n",
    "    u = {'i': 0}\n",
    "    z = {'t': 18.95, 'v': 4.183}\n",
    "    se.estimate(i, u, z)\n",
    "    print(se.x.mean)\n",
    "    print(\"\\tcorrect: {'tb': 18.95, 'qb': 7856.3254, 'qcp': 0, 'qcs': 0}\")"
   ]
  },
  {
   "source": [
    "## Conclusion\n",
    "Thank you for trying out this tutorial. See the examples in the `examples/` folder for more details on how to use the package. Any questions can be directed to Chris Teubert (christopher.a.teubert@nasa.gov)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}